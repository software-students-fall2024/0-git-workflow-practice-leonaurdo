
# Interesting Article Link
* [Thoughts on OpenAI's new o1 chain-of-thought models](https://simonwillison.net/2024/Sep/12/openai-o1/?utm_source=tldrwebdev)

# What I find interesting
As someone interested in the development of OpenAI's GPT models, I learned that the new released preview models, o1-preview and o1 mini, are not simply an upgrade of GPT-4o, but instead brings some major trade-offs between performance and new capabilities. These new capabilities include improved "reasoning", basically meaning that the new models are designed to spend longer time thinking before responding. The o1 model "learns to hone its chain of thought and refine the strategies it uses", is able to both recognize and correct mistakes, and tries difference approaches to a problem when the current one does not work. This "Chain of Thought" is able to even do tasks like solving crossword puzzles and calculate pH of relatively complex chemical solutions. Once these new models are more accessible to the public, I'm interested in trying them out and observe their development over time, and see how OpenAI will improve the test-time compute (time spent thinking). 

# Sewon Kim's Comment:
I found this article to be very interesting, especially how it mentions the process of thinking step-by-step being tested with the new models. I find it fascinating how the science of thinking patterns is being integrated into AI systems. I am excited to see what kinds of capabilities these new models will have!

# Ian Pompliano:
I thought this was a really cool article. I've used a few different models of GPT but never really knew what was so different between them. It was interesting to read this and learn about some of the capabiility differences and tradeoffs.